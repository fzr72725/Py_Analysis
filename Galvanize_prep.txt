201707:
Python note:
1. List comprehension:
result = [x+10 for x in my_list]

a = list('abcdefghijklmnopqrstuvwxyz')
b = list('phqgiumeaylnofdxjkrcvstzwb')
d = {x:y for x,y in zip(a,b)}

2. File operation:
my_file = open('hello.txt')
t = my_file.read()

# function strip is to remove \n
[l.strip() for l in my_file]

3. word/letter counter:
from collections import Counter
c = Counter(content)
* output is a dictionary

4. Set:
my_set = set(content)
* set is to have a unique element collection

5. Dictionary:
my_dict = dict((key,0) for key in my_set)

6. Other operation:
m += 1

string.lower()

function join is to turn a list into a string connected with specific char('' is no connector)
''.join(list)

print [x for x in range (1,5)]
*[1, 2, 3, 4]

print [i for i in range(8, 0, -1)]
[8, 7, 6, 5, 4, 3, 2, 1]

print range(5,-1,-1)
[5, 4, 3, 2, 1, 0]

7. pandas:
*to plot lists:
import matplotlib.pyplot as plt
%matplotlib inline
plt.plot(x,y)

8. Algorithms:
* This algorithm cheatsheet is super helpful!
http://bigocheatsheet.com/


Algorithm note:
1. Sorting:
* total number of value comparison and position exchange determine the efficiency of a sorting algo.
1) Bubble sort
def bubbleSort(alist):
    for passnum in range(len(alist)-1,0,-1):
        for i in range(passnum):
            if alist[i]>alist[i+1]:
                alist[i],alist[i+1] = alist[i+1],alist[i]
    return alist

2) Selection sort:
* Compare to bubble sort, selection sort reduce the exchange effort, each round, exchange only happen ONCE
* Each round, only the largest element is put to the last position of the list
def selectionSort(my_list):
    for index in range(len(my_list)-1,0,-1):
        largest = 0
        print index
        for idx in range(1,index+1):
            if my_list[idx]>my_list[largest]:
                largest = idx
        my_list[largest],my_list[index] = my_list[index],my_list[largest]
    return my_list
    
3) Insertion sort:
* O(n) = n**2
def insertionSort(my_list):
    for item in range(1,len(my_list)):
        for i in range(item-1,-1,-1):
            if my_list[i] > my_list[item]:
                my_list[i],my_list[item] = my_list[item],my_list[i]
                item = i
    return my_list



Statistics:
1. Permutation:
1) In general, n distinct objects can be arranged in n! ways.
2) The number of permutations of n distinct objects taken r at a time, Pnr=n*(n-1)*(n-2)...*(n-(r-1))
3) The number of different permutations of n objects of which n1 are of one kind, n2 are of a second kind, ... nk are of a k-th kind is n!/(n1!*n2!*...nk!)
4) There are \displaystyle{\left({n}-{1}\right)}!(n−1)! ways to arrange n distinct objects in a circle (where the clockwise and anti-clockwise arrangements are regarded as distinct.)

2. Combination:
1) Cnr=Pnr/r!
2) Cn0=Cnn=1
3) Cnr=Cn(n-r)

3. Probability terms:
1)Experiment: This is any process of observation or procedure that:

-Can be repeated (theoretically) an infinite number of times; and

-Has a well-defined set of possible outcomes.

2)Sample space: This is the set of all possible outcomes of an experiment.

3)Event: This is a subset of the sample space of an experiment.


4. Common probability problems:
1) Lottery odds:
http://www.intmath.com/counting-probability/singapore-toto.php
2) 

5. Conditional probability:
P(A|B): If A and B are two events, the probability that A occurs given that B has occurred
P(A|B)<student is French if he's female> = P(A⋂B)<student is French and female>/P(B)<student is female>

6. Independent and dependent probability:
1) Indepedent:
P(A⋂B) = P(A)*P(B)
2) Dependent:
P(A⋂B) = P(A)*P(B|A) = P(A)*P(B⋂A)/P(A)
* mutually exclusive events are NEVER independent, if A and B are mutually exclusive, P(A⋂B) = 0

7. non mutually exclusive events probability:
P(A or B) = P(A)+P(B)-P(A⋂B)

8. Bayes' Therom:
If E1 and E2 are mutually exclusive:
P(E1∣E)=P(E1⋂E)/[P(E2⋂E)+P(E1⋂E)]

9. If use conditional probability or P(A or B):
See if the given probability is describing seperate events (there are steps), if so, conditional probability, if not, like defective check, it's P(A or B)

10. Steps of solve a problem:
1) define all events
2) determine the relations between events(independent events<IE>/dependent events<DE>/ME/non-ME)
3) use appropriate formula:
IE:
P(A⋂B) = P(A)*P(B)
P(A or B) = P(A)+P(B)-P(A⋂B)

DE:
P(A⋂B) = P(A)*P(B|A) = P(A)*P(B⋂A)/P(A)
P(A or B) = P(A)+P(B)-P(A⋂B)

ME:
P(A⋂B) = 0
P(A or B) = P(A)+P(B)

non_ME:
P(A⋂B) = P(A)*P(B|A) = P(A)*P(B⋂A)/P(A)
P(A or B) = P(A)+P(B)-P(A⋂B)

11. Probability Distributions:
1) Random Variables
P(X) or P(x1), P(x2)...
2) Discrete probability distribution:


3)Probability density function:
* the area under the bell curve between two variables, The area under each curve is \displaystyle{1}1
∫abf(x)dx=P(a≤X≤b)

4)Probabilities As Relative Frequency
* If an experiment is performed a sufficient number of times, then in the long run, the relative frequency of an event is called the probability of that event occurring.

5) Expected Value:
* X represent a discrete random variable
E(X) = μ = Σ (xi × P(xi))
* is also called the mean of the probability distribution

4) Variance of a Random Variable
V(X) = σ2 = Σ[{X − E(X)}2 × P(X) ]

5) Standard Deviation of the Probability Distribution
σ=√V(X)
* describes the spread of the distribution. Small standard deviation means small spread, large standard deviation means large spread

12. The Binomial Probability Distribution
Binomial variable: only two kinds of outcome: true vs. false; yes vs. no, etc
1) the probability of successes in n binomial trials:
http://www.intmath.com/counting-probability/12-binomial-probability-distributions.php

2) Mean and Variance of Binomial Distribution:
E(X) = μ = np
V(X) = σ2 = npq

3) Binomial probability distribution is always finite. You can only have a finite number of x.

13. The Poisson Probability Distribution
http://www.intmath.com/counting-probability/13-poisson-probability-distribution.php
Time of success in two disjoint time intervals are independent
- car accident
- death rate in army due to horse kicking
- birth defect or mutation

E(X) = μ
V(X) = μ

14. Exponential distribution:
P(X) = λ e**(−λx)

15. Uniform Distribution:
P(X) = 1(b-a) if x is in [a,b], otherwise, P(X) = 0

16. Normal distribution:
1) How to calculate probability of normal distribution:
The probability of P(x < a) is: Φ(a)
The probability of P(x > a) is: 1 – Φ(a)
The probability of P(a < Z < b) is: Φ(b) – Φ(a)


2) empirical/three-sigma rule:
for a normal distribution:
68% of the data will fall within one standard deviation of the mean.
95% of the data will fall within two standard deviations of the mean.
99.7% of the data will fall within three standard deviations of the mean

17. Descriptive Statistics and inferential statistics
1) Descriptive Statistics
IQR= Q3-Q1
mode is the value of the number which appears the most frequent.

2) inferential statistics:
- confidence interval: 
*A Confidence Interval is a range of values we are fairly sure our true value lies in.
http://onlinelibrary.wiley.com/store/10.1002/9781119176459.app2/asset/app2.pdf;jsessionid=4A9786853B952C07AE11551CE4D33D64.f04t01?v=1&t=j5kdmt2y&s=adbcb36e33dea8411251d866fbef39d1f541b2b7
for 95% confidence interval:
X  ±  (Z*s/√(n)):
X is the mean
Z is 1.96for 95%
s is the standard deviation
n is the number of samples

or
p ± (Z*p(1-p)√(n))
p is the conversion rate, others mean the same as above


- conversion rate range
- statistical significance of an experiment: the likelihood of the difference of conversion rate between baseline and variation is not due to random chance
- To determine the observed difference in a statistical significance test, you will want to pay attention to two outputs: p-value and confidence interval around effect size.
- P-value: refers to the probability value of observing an effect from a sample. A p-value of < 0.05 is the conventional threshold for declaring statistical significance.
- Confidence interval around effect size: refers to the upper and lower bounds of what can happen with your experiment
- A statistically significant result isn’t attributed to chance and depends on two key variables: sample size and effect size.
- Sample size: refers to how large the sample for your experiment is.
- Effect size: refers to the size of the difference in results between two sample sets and indicates practical significance. If there is a small effect size (say a 0.1% increase in conversion rate) you will need a very large sample size to determine whether that difference is significant or just due to chance. However, if you observe a very large effect on your numbers, you will be able to validate it with a smaller sample size to a higher degree of confidence.
- Z score: how many standard diviations is a value away from the mean

3) General hypothesis testing
- The null hypothesis is essentially the "devil's advocate" position. That is, it assumes that whatever you are trying to prove did not happen (hint: it usually states that something equals zero). For example, the two different teaching methods did not result in different exam performances (i.e., zero difference).
The alternative hypothesis states the opposite and is usually the hypothesis you are trying to prove (e.g., the two different teaching methods did result in different exam performances). 
- significance level:
The level of statistical significance is often expressed as the so-called p-value
- how it works:
significance level/P value evaluates how well the sample data support the devil’s advocate argument that the null hypothesis is true. It measures how compatible your data are with the null hypothesis.

For example, suppose that a vaccine study produced a P value of 0.04. This P value indicates that if the vaccine had no effect, you’d obtain the observed difference or more in 4% of studies due to random sampling.

P values are calculated based on the assumptions that the null is true for the population and that the difference in the sample is caused entirely by random chance. Consequently, P values can’t tell you the probability that the null is true or false because it is 100% true from the perspective of the calculations.

https://www.khanacademy.org/math/statistics-probability/sampling-distributions-library/sample-means/v/sampling-distribution-of-the-sample-mean

https://www.khanacademy.org/math/statistics-probability/significance-tests-one-sample/tests-about-population-mean/v/hypothesis-testing-and-p-values

*** When plotting for hypothesis testing, that one big normal distribution looking curve is the "Sample distribution of sample mean", not the sample data itself! So each data point in that curve represent a sample and its mean. Hypothesis testing is built based on the central limit theorem. So it makes sense to conclude that if the alternative hypothesis mean is far away from the null hypothesis mean (z-score is large), the sample data from that alternative hypothesis probably does not follow the distribution of the null hypothesis data. Therefore we can prove that the alternative hypothesis generates new distribution of data.

- Type of errors:
In statistical hypothesis testing, a type I error is the incorrect rejection of a true null hypothesis (a "false positive"), while a type II error is incorrectly retaining a false null hypothesis (a "false negative").

19. Relationship between 2 quantitative variables:
y = a+bx
b = Slope = (N∑XY - (∑X)(∑Y)) / (N∑X**2 - (∑X)**2)
a = mean(Y)-bmean(X)

20. Modeling:
1) Linear Regression:
Predict a dependent continuous vale

2) Logistic Regression:
Predict the probability of a value, bounded between (0,1)
* Changing the $\beta_0$ value shifts the curve horizontally, whereas changing the $\beta_1$ value changes the slope of the curve.
* Positive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).

3) Cross Validation (CV):
- CV is used to select the best model to train. Here, "two different models" would be: linear regression vs neural network. Once we have used cross-validation to select the better performing model, we train that model (whether it be the linear regression or the neural network) on all the data. 
- k-folder CV: k iterations over the sample data using a proportion for training and CV
- After k-fold cross validation, we’ll get k different model estimation errors (e1, e2 …..ek)(MSE for quantitative responses, misclassification rate for qualtative responses). Then we take standard deviation of all errors. Lower value of standard deviation suggests our model does not vary a lot with different subset of training data.
4) Over-fitting:
Over-fitting is normally caused by high model complexity over the training data.
5) Bias–variance tradeoff:
- Error due to Bias: The error due to bias is taken as the difference between the expected (or average) prediction of our model and the correct value which we are trying to predict.
high bias = underfitting
- Error due to Variance: The error due to variance is taken as the variability of a model prediction for a given data point.(the variance from k-folder CV for example)
high variance = overfitting
6)Interpret coefficient:
Interpreting the "temp" coefficient ($\beta_1$):
It is the change in y divided by change in x, or the "slope".
Thus, a temperature increase of 1 degree Celsius is associated with a rental increase of 9.17 bikes.
This is not a statement of causation.
$\beta_1$ would be negative if an increase in temperature was associated with a decrease in rentals.

7)Ways to measure accuracy of linear regression model:
- MAE: mean of error
- MSE: mean of error square(variance)
- RMSE: mean of standard diviation
- Cross Validation: evaluating the variance/different models


21. Sensitivity and Specificity:
- True positive rate (or sensitivity): TPR=TP/(TP+FN)TPR=TP/(TP+FN)
- False positive rate: FPR=FP/(FP+TN)FPR=FP/(FP+TN)
- True negative rate (or specificity): TNR=TN/(FP+TN)
https://stats.stackexchange.com/questions/61829/relation-between-true-positive-false-positive-false-negative-and-true-negative
- ROC curve plots TP and TN when using different predicting positive threshold 
 
 
Note/Cheatsheet:
1. df.pivot_table('prop',index='year',columns='sex',aggfunc=sum)
or
df.pivot_table('births',index=last_letters,columns=['sex','year'],aggfunc=sum)
*Turns column values in different rows into column names
1.5 pd.read_csv(url,nams=['column1','column2'])
* use term "names" to assign column names
2. df.sort_values(by='prop',ascending=False)
*Sorts a dataframe by certain column
3. pd.plot(subplots=True,figsize=(12,10),grid=False,title="Number of births per year")
*Plot each Series in the dataframe
4. df.groupby(['year','sex'])
*Turn dataframe into certain groups using columns
4.5 df.groupby('stars').mean()
* groupby a variable, then get means for other variables in each group
5. df.concat(pieces, ignore_index=True)
*Merge multiple dataframes into one
6. np.cumsum(a=columnA)/df.columnA.cumsum()
*Calculate the cumulative sum of columnA
7. np.searchsorted(array,value)/Series.searchsorted(value)
*Return the index of the given value in the array/Serirs
8. def get_top1000(group):
       return group.sort_values(by='births',ascending=False)[:1000]
    
   top1000 = names.groupby(['year','sex']).apply(get_top1000)
*Define a function that will make changes to each group, then "groupby" a datagrame, then apply the defined function to each group in the GroupBy ojbect
9. get_last_letter = lambda x: x[:-1]
last_letters = names.name.map(get_last_letter)
*Using lambda to define a function, then run the function using map()
10. df.reindex(columns=[1910,1960,2010],level='year')
*Since years are the second level columns, it's hard to use column names to get the subset, so reindex can set the column level and get the subset
11. 
import matplotlib.pyplot as plt
figs, axes = plt.subplots(2,1,figsize=(10,8)) # 2,1 means 2x1 grid
letter_prop['M'].plot(kind='bar',rot=0,ax=axes[0],title='Male')
letter_prop['F'].plot(kind='bar',rot=0,ax=axes[1],title='Female',legend=False)
*When there are multiple levels of columns, pandas.plot cannot handle it, we can use matplotlib to do it by setting the subplots separately. 
12. letter_drop.ix[['d','n','y'],'M'].T
* ix can use either label or index to access dataframe rows
13. Series.values
Series.index
obj = Series([4,5,-7,3],index=['d','a','b','c'])
* Creates a Series object with specific index, this is desirable
13.5 glass.glass_type.value_counts().sort_index()
* Get counts for each value, then sort the counts
14. sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}
obj = Series(sdata)
*Create a Series object based on a dictionary, the dictionary key will be turned into index. A Series object can be treated as dictionary
15. pd.isnull(<a Series object>)
*Returns a Series object of boolean values, index of the examined Series object is still the index of the result Series object
16. 
data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'year': [2000, 2001, 2002, 2001, 2002],
'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}
frame = DataFrame(data)
*Creates dataframe from dictionaries with lists that have equal length, and you can specify the sequence of the columns by doing this: frame = DataFrame(data, columns=['year','state','pop'])
17. frame2['state']
frame2.year
*Two ways of retrieving a column from a dataframe
18. dataframe.T
* Tranposes the dataframe, meaning switch columns and rows
19. df.describe()
*Returns a bunch of statistical information about a dataframe values
20. dataframe.pct_change()
*Calculate the percent change in the dataframe for all columns
21.Series1.corr(Series2); Series1.cov(Series2)
*corr() Calculates the correlation of the two series(or two columns of a dataframe)
*cov() Calculates the covariance of the two series(or two columns of a dataframe)
22. DataFrame.corr();DataFrame.cov()
* similar to above, but return the whole matrix of all columns
23. DataFrame.isnull()/DataFrame.notnull()/DataFrame.dropna()/DataFrame.fillna()
* how dataframe deals with missing values
* missing value can be set using "np.nan"
24. DataFrame.fillna(DataFrame.mean())
* Fill na values with the mean of the data
25. dataframe.unstack()
* transform a multiple hierachy indexing dataframe into a one-level dataframe
26. JSON:
All keys in json object must be strings.
27. pd.ExcelFile('data.xls')
* pandas read in excel file as dataframe
28. pd.merge(df1,df2)
* join 2 dataframes using certain column(s)
29. pd.merge(left1, right1, left_on='key', right_index=True)
* merge on index, the example is saying that the index should be used as the merge key
30. arr = np.arange(12).reshape((3, 4))
* Create a matrix with integers
31. np.concatenate([arr,arr],axis=1)
* Merge 2 numpy arrays on the column axis
32. pd.concat([s1,s2,s3],axis=1,join='inner')
* Merge dataframes column by column (if leave axis blank, by default, it merge row by row, axis=0)
*(if leave join blank, by default, it does outer join)
33. pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])
* Create hierarchical index for cancatenated objects
34. np.where(pd.isnull(a), b, a)
* Form a new dataframe, when condition is met(a.element is null in this case), get element from object 1(b in thise case), else, get element from object 2(a in this case)
35. df1.combine_first(df2)
* “patching” missing data in the calling object with data from the object you pass
36. df.stack()
* Turn column names into row values, this is different from T
37. df.unstack()
* Turn index values into column names
* The general idea of stack() and unstack() is just "index<=>column name"
38. df.duplicated()
* Returns boolean Series to indicate if an element in the dataframe is duplicate
39. df.drop_duplicates()
* dedupe
40. Series.map(normally Series is a dataframe column)
* colume-wise data transformation, see page 196
41. pd.cut(ages, bins)
* Put elements in an array into a pre-defined "bin" to categories the elements
42. np.sign(dataframe)
* Return an array of 1 and -1 depending on the sign of the values in the target dataframe
43. DataFrame(np.random.randn(1000,4))/DataFrame(np.arange(6).reshape(3,2))
*Two ways of creating dataframe using random numbers
44. pd.get_dummies(df['key']v prefix='key')
* key column is a categorical variable with k values, this method convert it to a k-column dataframe

page 206











